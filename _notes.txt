TODO

• [Test] Network
• [Test] DeltaHandler

• [Optimization] Flip Matrix (see MatrixAlt)
• [Optimization] Store the zL values somewhere to cut down on DotProduct calls
• [Optimization] Research how to handle "dead" neurons on continuous backpropagation
• [Optimization] Make the size of the hidden layer(s) variable based on neuron activation

• [Interface] Accept JSON as Input/Output and map back on Output from .run
• [Interface] "Load" functionality to start with existing weights and biases

Example: Training Data
  {
    input: { [key]: number },
      -> Any length of object keys
      -> Persists which order the keys are put into input activation layer
      -> Convert to number[] and plug into input array
    output: { [key]: number }
      -> Any length of object keys
      -> Persists which order the keys are put into expected layer
      -> Convert to number[] and plug into expected array
  }

Example: Run (post training)
  Should return output array mapped to { [key]: number } from training data