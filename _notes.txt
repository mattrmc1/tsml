TODO

• [Test] Network
• [Test] DeltaHandler

• [Optimization] Flip Matrix (see MatrixAlt)
• [Optimization] Store the zL values somewhere to cut down on DotProduct calls
• [Optimization] Research how to handle "dead" neurons on continuous backpropagation
• [Optimization] Make the size of the hidden layer(s) variable based on neuron activation

• [Interface] Refactor constructor/config to be clearer
• [Interface] "Load" functionality to start with existing weights and biases

Training Example:
[
  {
    input: {
      r: 0.5,
      g: 0.3,
      b: 0.6,
      a: 0.2
    },
    output: {
      dark: 0,
      light: 1
    }
  },
  {
    input: {
      g: 0.9,
      r: 0.9,
      b: 0.9,
      a: 0.9
    },
    output: {
      dark: 1,
      light: 0
    }
  }
];

Running Example
(IN):   { r, g, b, a }
(OUT):  { dark, light }